"""
Final cleanup for onnx_translation package compatibility
Removes unnecessary files and keeps only required ones
"""

from pathlib import Path
import os

OUTPUT_DIR = Path(__file__).parent.parent / "onnx_models" / "en-tr"

print("\n" + "="*60)
print("Final Cleanup for onnx_translation Package")
print("="*60 + "\n")

# Required files for onnx_translation package
REQUIRED_FILES = [
    "encoder_model.onnx",
    "decoder_model.onnx",
    "vocab.json",
    "tokenizer_config.json",
    "generation_config.json",
    "special_tokens_map.json",  # Optional but small
    "config.json",  # Keep for reference
]

# Files to delete
DELETE_FILES = [
    "decoder_with_past_model.onnx",  # Not used by package (84MB)
    "source.spm",  # Not used (794KB)
    "target.spm",  # Not used (838KB)
    "README.md",  # Will regenerate
]

print("Removing unnecessary files...\n")

total_deleted = 0
for filename in DELETE_FILES:
    filepath = OUTPUT_DIR / filename
    if filepath.exists():
        size_mb = filepath.stat().st_size / (1024 * 1024)
        filepath.unlink()
        total_deleted += size_mb
        print(f"✓ Deleted: {filename:40s} ({size_mb:.2f} MB)")
    else:
        print(f"  Skip: {filename:40s} (not found)")

print(f"\nSpace saved: {total_deleted:.2f} MB")

# Verify required files exist
print("\n" + "="*60)
print("Verifying Required Files")
print("="*60 + "\n")

all_good = True
total_size = 0

for filename in REQUIRED_FILES:
    filepath = OUTPUT_DIR / filename
    if filepath.exists():
        size_mb = filepath.stat().st_size / (1024 * 1024)
        total_size += size_mb
        print(f"✓ {filename:40s} {size_mb:>8.2f} MB")
    else:
        print(f"✗ MISSING: {filename}")
        all_good = False

print(f"\n{'Total size:':40s} {total_size:>8.2f} MB")

if all_good:
    print("\n✓ All required files present!")
    print("✓ Ready for onnx_translation package")
else:
    print("\n✗ Some required files are missing!")

# Create updated README
readme_content = """# English to Turkish Translation Model

**Source:** Helsinki-NLP/opus-tatoeba-en-tr  
**Format:** ONNX (Mobile Optimized for onnx_translation package)  
**Package:** onnx_translation ^0.1.2

## Files

### Required by onnx_translation:
- `encoder_model.onnx` (50.17 MB) - Encoder model
- `decoder_model.onnx` (87.73 MB) - Decoder model
- `vocab.json` (1.65 MB) - Tokenizer vocabulary
- `tokenizer_config.json` (888 B) - Tokenizer configuration
- `generation_config.json` (304 B) - Generation parameters

### Additional:
- `special_tokens_map.json` (439 B) - Special tokens
- `config.json` (1 KB) - Model configuration

**Total Size:** ~140 MB (optimized for Flutter)

## Usage in Flutter

```dart
import 'package:onnx_translation/onnx_translation.dart';

final model = OnnxModel();
await model.init(modelBasePath: 'assets/onnx_models/en-tr');

// Translate
final translated = await model.runModel(
  "Hello, how are you?",
  initialLangToken: '>>tr<<'  // Target Turkish
);
print(translated); // "Merhaba, nasılsın?"
```

## Test Translations

```
✅ "Hello, how are you?" → "Merhaba, nasılsın?"
✅ "Good morning" → "Günaydın"
✅ "Thank you" → "Teşekkür ederim"
```

## pubspec.yaml

```yaml
dependencies:
  onnx_translation: ^0.1.2
  onnxruntime: ^1.4.1
  ffi: ^2.0.0

flutter:
  assets:
    - assets/onnx_models/en-tr/
```

---

*Generated by scripts/final_cleanup.py*
*Last updated: 2025-11-01*
"""

readme_path = OUTPUT_DIR / "README.md"
with open(readme_path, 'w', encoding='utf-8') as f:
    f.write(readme_content)

print(f"\n✓ Created new README.md with usage instructions\n")
print("="*60)
print("✓ Cleanup Complete!")
print("="*60 + "\n")
